=========== start train the brain age estimation model ===========

 ==========> Using 8 processes for data loader.
(3712,) 3712
(752,) 752
 ==========> Training is getting started...
 ==========> Training takes 150 epochs.
Epoch: [0 / 150]   [step 0/232]	Loss1 2962.448 (2962.448)	Loss2 706.868 (706.868)	Loss 10031.1260 (10031.1260)	MAE 49.850 (49.850)	
Epoch: [0 / 150]   [step 40/232]	Loss1 171.165 (448.157)	Loss2 321.222 (430.037)	Loss 3383.3850 (4748.5283)	MAE 11.324 (16.313)	
Epoch: [0 / 150]   [step 80/232]	Loss1 96.739 (342.837)	Loss2 160.337 (402.336)	Loss 1700.1132 (4366.1997)	MAE 7.704 (14.331)	
Epoch: [0 / 150]   [step 120/232]	Loss1 167.949 (297.167)	Loss2 320.478 (377.327)	Loss 3372.7324 (4070.4373)	MAE 9.851 (13.342)	
Epoch: [0 / 150]   [step 160/232]	Loss1 148.812 (268.579)	Loss2 249.654 (356.438)	Loss 2645.3477 (3832.9570)	MAE 9.871 (12.683)	
Epoch: [0 / 150]   [step 200/232]	Loss1 124.269 (258.136)	Loss2 135.730 (341.184)	Loss 1481.5726 (3669.9768)	MAE 9.284 (12.426)	
Valid: [steps 47], Loss 3494.4534,  MAE:  31.9280

*learning rate 1.00e-03*

=======>   Best at epoch 0, valid MAE 31.928002

=======>   This is the best model !!! It has been saved!!!!!!


Epoch: [1 / 150]   [step 0/232]	Loss1 161.165 (161.165)	Loss2 242.039 (242.039)	Loss 2581.5574 (2581.5574)	MAE 10.304 (10.304)	
Epoch: [1 / 150]   [step 40/232]	Loss1 180.474 (173.525)	Loss2 153.724 (246.250)	Loss 1717.7148 (2636.0303)	MAE 11.143 (10.389)	
Epoch: [1 / 150]   [step 80/232]	Loss1 104.744 (178.636)	Loss2 118.127 (231.221)	Loss 1286.0144 (2490.8477)	MAE 7.403 (10.567)	
Epoch: [1 / 150]   [step 120/232]	Loss1 90.388 (170.904)	Loss2 125.351 (223.345)	Loss 1343.8998 (2404.3506)	MAE 7.336 (10.287)	
Epoch: [1 / 150]   [step 160/232]	Loss1 118.829 (162.514)	Loss2 205.590 (225.476)	Loss 2174.7261 (2417.2771)	MAE 8.713 (9.966)	
Epoch: [1 / 150]   [step 200/232]	Loss1 326.562 (168.107)	Loss2 593.180 (227.360)	Loss 6258.3613 (2441.7070)	MAE 15.432 (10.131)	
Valid: [steps 47], Loss 2919.1270,  MAE:  17.4159

*learning rate 1.00e-03*

=======>   Best at epoch 1, valid MAE 17.415873

=======>   This is the best model !!! It has been saved!!!!!!


Epoch: [2 / 150]   [step 0/232]	Loss1 132.203 (132.203)	Loss2 364.246 (364.246)	Loss 3774.6602 (3774.6602)	MAE 8.579 (8.579)	
Epoch: [2 / 150]   [step 40/232]	Loss1 50.122 (151.651)	Loss2 84.104 (207.684)	Loss 891.1600 (2228.4949)	MAE 5.667 (9.422)	
Epoch: [2 / 150]   [step 80/232]	Loss1 137.179 (171.127)	Loss2 146.093 (208.991)	Loss 1598.1128 (2261.0386)	MAE 9.270 (10.042)	
Epoch: [2 / 150]   [step 120/232]	Loss1 193.562 (151.498)	Loss2 196.597 (204.221)	Loss 2159.5356 (2193.7119)	MAE 9.994 (9.333)	
Epoch: [2 / 150]   [step 160/232]	Loss1 124.583 (145.457)	Loss2 302.331 (200.751)	Loss 3147.8882 (2152.9656)	MAE 8.973 (9.154)	
Epoch: [2 / 150]   [step 200/232]	Loss1 123.553 (149.044)	Loss2 196.984 (203.739)	Loss 2093.3904 (2186.4321)	MAE 8.971 (9.339)	
Valid: [steps 47], Loss 1649.6617,  MAE:  9.1306

*learning rate 1.00e-03*

=======>   Best at epoch 2, valid MAE 9.130632

=======>   This is the best model !!! It has been saved!!!!!!


Epoch: [3 / 150]   [step 0/232]	Loss1 374.628 (374.628)	Loss2 64.069 (64.069)	Loss 1015.3150 (1015.3150)	MAE 17.923 (17.923)	
Epoch: [3 / 150]   [step 40/232]	Loss1 52.975 (135.792)	Loss2 39.440 (186.008)	Loss 447.3772 (1995.8679)	MAE 6.185 (8.770)	
Epoch: [3 / 150]   [step 80/232]	Loss1 27.487 (121.240)	Loss2 27.827 (175.089)	Loss 305.7607 (1872.1244)	MAE 4.493 (8.308)	
Epoch: [3 / 150]   [step 120/232]	Loss1 99.083 (119.163)	Loss2 89.715 (172.632)	Loss 996.2293 (1845.4862)	MAE 7.592 (8.234)	
Epoch: [3 / 150]   [step 160/232]	Loss1 242.075 (132.335)	Loss2 200.182 (182.357)	Loss 2243.8909 (1955.9092)	MAE 12.814 (8.723)	
Epoch: [3 / 150]   [step 200/232]	Loss1 163.082 (131.308)	Loss2 249.775 (179.696)	Loss 2660.8289 (1928.2639)	MAE 8.957 (8.701)	
Valid: [steps 47], Loss 1557.1393,  MAE:  9.0227

*learning rate 1.00e-03*

=======>   Best at epoch 3, valid MAE 9.022717

=======>   This is the best model !!! It has been saved!!!!!!


Epoch: [4 / 150]   [step 0/232]	Loss1 143.282 (143.282)	Loss2 203.549 (203.549)	Loss 2178.7742 (2178.7742)	MAE 9.590 (9.590)	
Epoch: [4 / 150]   [step 40/232]	Loss1 306.847 (110.177)	Loss2 406.865 (159.241)	Loss 4375.4956 (1702.5820)	MAE 14.479 (7.958)	
Epoch: [4 / 150]   [step 80/232]	Loss1 79.624 (106.306)	Loss2 152.224 (153.512)	Loss 1601.8665 (1641.4232)	MAE 7.182 (7.820)	
Epoch: [4 / 150]   [step 120/232]	Loss1 87.328 (111.349)	Loss2 270.861 (162.332)	Loss 2795.9375 (1734.6716)	MAE 7.465 (8.121)	
Epoch: [4 / 150]   [step 160/232]	Loss1 68.482 (111.332)	Loss2 157.986 (161.719)	Loss 1648.3431 (1728.5262)	MAE 6.724 (8.077)	
Epoch: [4 / 150]   [step 200/232]	Loss1 126.621 (109.700)	Loss2 204.080 (159.140)	Loss 2167.4170 (1701.1021)	MAE 8.036 (7.987)	
Valid: [steps 47], Loss 1640.4067,  MAE:  7.8814

*learning rate 1.00e-03*

=======>   Best at epoch 4, valid MAE 7.881368

=======>   This is the best model !!! It has been saved!!!!!!


Epoch: [5 / 150]   [step 0/232]	Loss1 103.413 (103.413)	Loss2 178.439 (178.439)	Loss 1887.8046 (1887.8046)	MAE 7.447 (7.447)	
Epoch: [5 / 150]   [step 40/232]	Loss1 113.945 (107.322)	Loss2 317.546 (149.640)	Loss 3289.4072 (1603.7223)	MAE 8.679 (7.962)	
Epoch: [5 / 150]   [step 80/232]	Loss1 76.103 (100.561)	Loss2 41.474 (139.095)	Loss 490.8393 (1491.5142)	MAE 6.587 (7.636)	
Epoch: [5 / 150]   [step 120/232]	Loss1 63.353 (98.036)	Loss2 77.013 (139.202)	Loss 833.4786 (1490.0591)	MAE 6.142 (7.514)	
Epoch: [5 / 150]   [step 160/232]	Loss1 67.481 (96.023)	Loss2 134.958 (141.999)	Loss 1417.0624 (1516.0165)	MAE 7.272 (7.438)	
Epoch: [5 / 150]   [step 200/232]	Loss1 148.995 (95.236)	Loss2 95.444 (141.113)	Loss 1103.4343 (1506.3705)	MAE 10.252 (7.406)	
Valid: [steps 47], Loss 1486.0609,  MAE:  10.5402

*learning rate 1.00e-03*

EarlyStopping counter: 1 out of 20


Epoch: [6 / 150]   [step 0/232]	Loss1 78.559 (78.559)	Loss2 169.505 (169.505)	Loss 1773.6072 (1773.6072)	MAE 7.267 (7.267)	
Epoch: [6 / 150]   [step 40/232]	Loss1 139.738 (87.677)	Loss2 153.899 (128.103)	Loss 1678.7305 (1368.7057)	MAE 9.428 (7.262)	
Epoch: [6 / 150]   [step 80/232]	Loss1 106.215 (82.666)	Loss2 19.650 (122.143)	Loss 302.7162 (1304.0991)	MAE 8.906 (6.857)	
Epoch: [6 / 150]   [step 120/232]	Loss1 70.638 (83.837)	Loss2 101.043 (123.640)	Loss 1081.0660 (1320.2363)	MAE 6.517 (6.927)	
Epoch: [6 / 150]   [step 160/232]	Loss1 56.823 (83.597)	Loss2 87.727 (122.837)	Loss 934.0959 (1311.9653)	MAE 5.893 (6.892)	
Epoch: [6 / 150]   [step 200/232]	Loss1 137.845 (83.576)	Loss2 128.683 (122.617)	Loss 1424.6699 (1309.7484)	MAE 9.826 (6.852)	
Valid: [steps 47], Loss 2235.4709,  MAE:  18.2425

*learning rate 1.00e-03*

EarlyStopping counter: 2 out of 20


Epoch: [7 / 150]   [step 0/232]	Loss1 42.401 (42.401)	Loss2 24.392 (24.392)	Loss 286.3168 (286.3168)	MAE 5.190 (5.190)	
Epoch: [7 / 150]   [step 40/232]	Loss1 58.033 (79.203)	Loss2 172.183 (117.235)	Loss 1779.8602 (1251.5537)	MAE 5.810 (6.725)	
Epoch: [7 / 150]   [step 80/232]	Loss1 120.654 (80.957)	Loss2 289.802 (123.670)	Loss 3018.6692 (1317.6591)	MAE 8.873 (6.871)	
Epoch: [7 / 150]   [step 120/232]	Loss1 73.498 (77.257)	Loss2 95.416 (122.476)	Loss 1027.6537 (1302.0203)	MAE 6.118 (6.625)	
Epoch: [7 / 150]   [step 160/232]	Loss1 74.804 (79.315)	Loss2 52.253 (119.266)	Loss 597.3311 (1271.9758)	MAE 7.134 (6.735)	
Epoch: [7 / 150]   [step 200/232]	Loss1 144.848 (80.881)	Loss2 96.865 (119.469)	Loss 1113.4943 (1275.5750)	MAE 9.898 (6.817)	
Valid: [steps 47], Loss 2387.1230,  MAE:  15.7799

*learning rate 1.00e-03*

EarlyStopping counter: 3 out of 20


Epoch: [8 / 150]   [step 0/232]	Loss1 74.784 (74.784)	Loss2 56.079 (56.079)	Loss 635.5699 (635.5699)	MAE 6.733 (6.733)	
Epoch: [8 / 150]   [step 40/232]	Loss1 61.312 (66.957)	Loss2 153.059 (100.608)	Loss 1591.9005 (1073.0356)	MAE 6.558 (5.960)	
Epoch: [8 / 150]   [step 80/232]	Loss1 78.333 (74.087)	Loss2 92.190 (104.556)	Loss 1000.2368 (1119.6498)	MAE 7.911 (6.426)	
Epoch: [8 / 150]   [step 120/232]	Loss1 65.697 (75.454)	Loss2 85.182 (104.835)	Loss 917.5150 (1123.8037)	MAE 6.683 (6.528)	
Epoch: [8 / 150]   [step 160/232]	Loss1 61.670 (73.865)	Loss2 135.894 (102.154)	Loss 1420.6097 (1095.4072)	MAE 6.289 (6.461)	
Epoch: [8 / 150]   [step 200/232]	Loss1 65.099 (73.416)	Loss2 51.131 (103.975)	Loss 576.4123 (1113.1702)	MAE 6.078 (6.433)	
Valid: [steps 47], Loss 1982.4137,  MAE:  9.9850

*learning rate 1.00e-03*

EarlyStopping counter: 4 out of 20


Epoch: [9 / 150]   [step 0/232]	Loss1 48.592 (48.592)	Loss2 44.648 (44.648)	Loss 495.0695 (495.0695)	MAE 5.574 (5.574)	
Epoch: [9 / 150]   [step 40/232]	Loss1 44.191 (57.353)	Loss2 88.277 (101.013)	Loss 926.9631 (1067.4795)	MAE 5.043 (5.724)	
Epoch: [9 / 150]   [step 80/232]	Loss1 27.742 (60.139)	Loss2 26.815 (95.940)	Loss 295.8958 (1019.5397)	MAE 3.695 (5.901)	
Epoch: [9 / 150]   [step 120/232]	Loss1 62.097 (60.448)	Loss2 90.116 (93.875)	Loss 963.2539 (999.2017)	MAE 6.311 (5.931)	
Epoch: [9 / 150]   [step 160/232]	Loss1 47.546 (59.164)	Loss2 59.426 (91.373)	Loss 641.8054 (972.8920)	MAE 4.398 (5.824)	
Epoch: [9 / 150]   [step 200/232]	Loss1 66.078 (59.281)	Loss2 139.444 (89.378)	Loss 1460.5172 (953.0602)	MAE 5.823 (5.810)	
Valid: [steps 47], Loss 1306.3380,  MAE:  8.4009

*learning rate 1.00e-03*

EarlyStopping counter: 5 out of 20


Epoch: [10 / 150]   [step 0/232]	Loss1 66.550 (66.550)	Loss2 46.393 (46.393)	Loss 530.4778 (530.4778)	MAE 6.680 (6.680)	
Epoch: [10 / 150]   [step 40/232]	Loss1 67.973 (65.634)	Loss2 87.135 (92.562)	Loss 939.3192 (991.2550)	MAE 6.593 (6.185)	
Epoch: [10 / 150]   [step 80/232]	Loss1 33.935 (65.812)	Loss2 45.479 (83.603)	Loss 488.7268 (901.8436)	MAE 4.607 (6.136)	
Epoch: [10 / 150]   [step 120/232]	Loss1 58.326 (63.766)	Loss2 117.300 (85.146)	Loss 1231.3223 (915.2292)	MAE 6.054 (5.982)	
Epoch: [10 / 150]   [step 160/232]	Loss1 50.973 (62.767)	Loss2 117.120 (84.134)	Loss 1222.1686 (904.1063)	MAE 5.785 (5.995)	
Epoch: [10 / 150]   [step 200/232]	Loss1 24.280 (65.448)	Loss2 51.631 (81.784)	Loss 540.5869 (883.2881)	MAE 4.161 (6.139)	
Valid: [steps 47], Loss 1637.0236,  MAE:  12.8361

*learning rate 5.00e-04*

EarlyStopping counter: 6 out of 20


Epoch: [11 / 150]   [step 0/232]	Loss1 67.818 (67.818)	Loss2 30.654 (30.654)	Loss 374.3618 (374.3618)	MAE 6.411 (6.411)	
Epoch: [11 / 150]   [step 40/232]	Loss1 39.443 (62.051)	Loss2 90.252 (73.510)	Loss 941.9615 (797.1494)	MAE 5.169 (6.068)	
Epoch: [11 / 150]   [step 80/232]	Loss1 45.602 (56.254)	Loss2 70.996 (75.351)	Loss 755.5603 (809.7640)	MAE 5.654 (5.745)	
Epoch: [11 / 150]   [step 120/232]	Loss1 44.563 (53.786)	Loss2 54.205 (70.712)	Loss 586.6158 (760.9097)	MAE 4.933 (5.614)	
Epoch: [11 / 150]   [step 160/232]	Loss1 55.722 (52.842)	Loss2 120.815 (71.316)	Loss 1263.8744 (766.0052)	MAE 5.718 (5.515)	
Epoch: [11 / 150]   [step 200/232]	Loss1 21.657 (53.544)	Loss2 33.542 (70.767)	Loss 357.0766 (761.2142)	MAE 3.503 (5.537)	
Valid: [steps 47], Loss 803.9702,  MAE:  5.3773

*learning rate 5.00e-04*

=======>   Best at epoch 11, valid MAE 5.377292

=======>   This is the best model !!! It has been saved!!!!!!


Epoch: [12 / 150]   [step 0/232]	Loss1 31.000 (31.000)	Loss2 39.061 (39.061)	Loss 421.6136 (421.6136)	MAE 4.601 (4.601)	
Epoch: [12 / 150]   [step 40/232]	Loss1 28.992 (35.432)	Loss2 70.729 (54.750)	Loss 736.2868 (582.9320)	MAE 4.305 (4.539)	
Epoch: [12 / 150]   [step 80/232]	Loss1 272.055 (42.733)	Loss2 92.617 (62.337)	Loss 1198.2258 (666.0988)	MAE 15.032 (4.892)	
Epoch: [12 / 150]   [step 120/232]	Loss1 34.964 (45.213)	Loss2 40.653 (64.089)	Loss 441.4926 (686.1010)	MAE 4.966 (5.045)	
Epoch: [12 / 150]   [step 160/232]	Loss1 131.322 (49.318)	Loss2 123.156 (66.804)	Loss 1362.8845 (717.3603)	MAE 9.453 (5.308)	
Epoch: [12 / 150]   [step 200/232]	Loss1 66.792 (48.439)	Loss2 153.936 (65.608)	Loss 1606.1479 (704.5231)	MAE 6.146 (5.278)	
Valid: [steps 47], Loss 917.0760,  MAE:  5.2774

*learning rate 5.00e-04*

=======>   Best at epoch 12, valid MAE 5.277376

=======>   This is the best model !!! It has been saved!!!!!!


Epoch: [13 / 150]   [step 0/232]	Loss1 37.289 (37.289)	Loss2 48.214 (48.214)	Loss 519.4339 (519.4339)	MAE 4.804 (4.804)	
Epoch: [13 / 150]   [step 40/232]	Loss1 36.158 (37.421)	Loss2 42.420 (42.468)	Loss 460.3572 (462.0973)	MAE 4.301 (4.675)	
Epoch: [13 / 150]   [step 80/232]	Loss1 21.740 (44.078)	Loss2 34.513 (51.608)	Loss 366.8663 (560.1566)	MAE 3.795 (5.017)	
Epoch: [13 / 150]   [step 120/232]	Loss1 85.232 (44.771)	Loss2 151.236 (54.351)	Loss 1597.5874 (588.2773)	MAE 6.915 (5.073)	
Epoch: [13 / 150]   [step 160/232]	Loss1 89.678 (44.545)	Loss2 38.297 (55.167)	Loss 472.6527 (596.2109)	MAE 8.236 (5.081)	
Epoch: [13 / 150]   [step 200/232]	Loss1 16.223 (43.690)	Loss2 24.960 (53.150)	Loss 265.8252 (575.1907)	MAE 3.141 (5.012)	
Valid: [steps 47], Loss 935.1827,  MAE:  7.5553

*learning rate 5.00e-04*

EarlyStopping counter: 1 out of 20


Epoch: [14 / 150]   [step 0/232]	Loss1 47.076 (47.076)	Loss2 81.861 (81.861)	Loss 865.6910 (865.6910)	MAE 5.890 (5.890)	
Epoch: [14 / 150]   [step 40/232]	Loss1 18.392 (37.228)	Loss2 40.456 (50.956)	Loss 422.9541 (546.7925)	MAE 3.047 (4.653)	
Epoch: [14 / 150]   [step 80/232]	Loss1 16.711 (35.203)	Loss2 14.809 (48.945)	Loss 164.7992 (524.6578)	MAE 3.328 (4.539)	
Epoch: [14 / 150]   [step 120/232]	Loss1 17.805 (38.657)	Loss2 45.951 (50.049)	Loss 477.3195 (539.1457)	MAE 3.511 (4.722)	
Epoch: [14 / 150]   [step 160/232]	Loss1 67.999 (38.451)	Loss2 22.931 (49.038)	Loss 297.3097 (528.8335)	MAE 7.195 (4.681)	
Epoch: [14 / 150]   [step 200/232]	Loss1 32.131 (38.852)	Loss2 46.594 (49.123)	Loss 498.0702 (530.0840)	MAE 4.354 (4.715)	
Valid: [steps 47], Loss 892.7253,  MAE:  5.2852

*learning rate 5.00e-04*

EarlyStopping counter: 2 out of 20


Epoch: [15 / 150]   [step 0/232]	Loss1 28.706 (28.706)	Loss2 40.226 (40.226)	Loss 430.9662 (430.9662)	MAE 4.668 (4.668)	
Epoch: [15 / 150]   [step 40/232]	Loss1 26.145 (36.900)	Loss2 90.391 (51.646)	Loss 930.0529 (553.3552)	MAE 3.800 (4.588)	
Epoch: [15 / 150]   [step 80/232]	Loss1 18.868 (41.755)	Loss2 20.663 (50.259)	Loss 225.4974 (544.3455)	MAE 3.058 (4.927)	
Epoch: [15 / 150]   [step 120/232]	Loss1 53.411 (40.131)	Loss2 117.590 (47.746)	Loss 1229.3073 (517.5961)	MAE 5.712 (4.784)	
Epoch: [15 / 150]   [step 160/232]	Loss1 14.552 (40.405)	Loss2 5.363 (46.616)	Loss 68.1869 (506.5675)	MAE 3.108 (4.803)	
Epoch: [15 / 150]   [step 200/232]	Loss1 20.813 (40.063)	Loss2 58.038 (48.424)	Loss 601.1899 (524.3019)	MAE 3.692 (4.784)	
Valid: [steps 47], Loss 899.9539,  MAE:  6.1763

*learning rate 5.00e-04*

EarlyStopping counter: 3 out of 20


Epoch: [16 / 150]   [step 0/232]	Loss1 120.243 (120.243)	Loss2 78.466 (78.466)	Loss 904.9033 (904.9033)	MAE 8.943 (8.943)	
Epoch: [16 / 150]   [step 40/232]	Loss1 16.924 (37.200)	Loss2 26.625 (44.777)	Loss 283.1696 (484.9710)	MAE 3.291 (4.735)	
Epoch: [16 / 150]   [step 80/232]	Loss1 81.458 (35.468)	Loss2 46.739 (45.496)	Loss 548.8524 (490.4254)	MAE 7.481 (4.586)	
Epoch: [16 / 150]   [step 120/232]	Loss1 29.207 (38.840)	Loss2 47.431 (47.721)	Loss 503.5183 (516.0535)	MAE 4.086 (4.768)	
Epoch: [16 / 150]   [step 160/232]	Loss1 49.775 (37.308)	Loss2 22.921 (47.148)	Loss 278.9871 (508.7866)	MAE 5.797 (4.661)	
Epoch: [16 / 150]   [step 200/232]	Loss1 16.461 (38.699)	Loss2 30.592 (47.280)	Loss 322.3826 (511.4981)	MAE 3.069 (4.757)	
Valid: [steps 47], Loss 1009.6370,  MAE:  5.7531

*learning rate 5.00e-04*

EarlyStopping counter: 4 out of 20


Epoch: [17 / 150]   [step 0/232]	Loss1 57.081 (57.081)	Loss2 34.405 (34.405)	Loss 401.1273 (401.1273)	MAE 6.325 (6.325)	
Epoch: [17 / 150]   [step 40/232]	Loss1 35.855 (29.963)	Loss2 20.628 (37.345)	Loss 242.1306 (403.4127)	MAE 4.786 (4.123)	
Epoch: [17 / 150]   [step 80/232]	Loss1 37.576 (31.977)	Loss2 11.892 (39.253)	Loss 156.5000 (424.5095)	MAE 5.032 (4.274)	
Epoch: [17 / 150]   [step 120/232]	Loss1 24.401 (34.020)	Loss2 27.729 (42.722)	Loss 301.6954 (461.2445)	MAE 4.060 (4.393)	
Epoch: [17 / 150]   [step 160/232]	Loss1 15.639 (33.190)	Loss2 39.944 (42.964)	Loss 415.0780 (462.8286)	MAE 2.906 (4.344)	
Epoch: [17 / 150]   [step 200/232]	Loss1 10.912 (34.249)	Loss2 14.964 (43.427)	Loss 160.5507 (468.5150)	MAE 2.501 (4.381)	
Valid: [steps 47], Loss 836.6554,  MAE:  5.8486

*learning rate 5.00e-04*

EarlyStopping counter: 5 out of 20


Epoch: [18 / 150]   [step 0/232]	Loss1 11.236 (11.236)	Loss2 25.642 (25.642)	Loss 267.6543 (267.6543)	MAE 3.018 (3.018)	
Epoch: [18 / 150]   [step 40/232]	Loss1 18.739 (27.993)	Loss2 30.723 (35.641)	Loss 325.9653 (384.4000)	MAE 3.513 (4.043)	
Epoch: [18 / 150]   [step 80/232]	Loss1 20.546 (30.577)	Loss2 23.759 (39.583)	Loss 258.1369 (426.4033)	MAE 3.381 (4.230)	
Epoch: [18 / 150]   [step 120/232]	Loss1 28.046 (33.152)	Loss2 36.642 (37.977)	Loss 394.4680 (412.9236)	MAE 4.387 (4.432)	
Epoch: [18 / 150]   [step 160/232]	Loss1 19.655 (32.419)	Loss2 36.856 (36.954)	Loss 388.2136 (401.9556)	MAE 3.315 (4.416)	
Epoch: [18 / 150]   [step 200/232]	Loss1 15.116 (30.293)	Loss2 16.014 (34.968)	Loss 175.2575 (379.9714)	MAE 3.180 (4.249)	
Valid: [steps 47], Loss 970.6443,  MAE:  8.6117

*learning rate 2.50e-04*

EarlyStopping counter: 6 out of 20


Epoch: [19 / 150]   [step 0/232]	Loss1 8.425 (8.425)	Loss2 13.788 (13.788)	Loss 146.3028 (146.3028)	MAE 2.134 (2.134)	
Epoch: [19 / 150]   [step 40/232]	Loss1 18.156 (34.011)	Loss2 24.080 (35.704)	Loss 258.9558 (391.0476)	MAE 3.325 (4.418)	
Epoch: [19 / 150]   [step 80/232]	Loss1 6.942 (30.800)	Loss2 15.147 (33.294)	Loss 158.4123 (363.7404)	MAE 2.259 (4.224)	
Epoch: [19 / 150]   [step 120/232]	Loss1 68.371 (28.191)	Loss2 38.974 (30.750)	Loss 458.1095 (335.6880)	MAE 6.641 (4.043)	
Epoch: [19 / 150]   [step 160/232]	Loss1 21.154 (28.741)	Loss2 36.790 (31.496)	Loss 389.0542 (343.7039)	MAE 3.706 (4.099)	
Epoch: [19 / 150]   [step 200/232]	Loss1 20.172 (27.789)	Loss2 22.492 (30.783)	Loss 245.0901 (335.6169)	MAE 3.506 (4.047)	
Valid: [steps 47], Loss 829.7833,  MAE:  5.2390

*learning rate 2.50e-04*

=======>   Best at epoch 19, valid MAE 5.238969

=======>   This is the best model !!! It has been saved!!!!!!


Epoch: [20 / 150]   [step 0/232]	Loss1 48.090 (48.090)	Loss2 18.178 (18.178)	Loss 229.8686 (229.8686)	MAE 6.430 (6.430)	
Epoch: [20 / 150]   [step 40/232]	Loss1 9.266 (21.732)	Loss2 6.933 (30.322)	Loss 78.5991 (324.9525)	MAE 2.459 (3.655)	
Epoch: [20 / 150]   [step 80/232]	Loss1 6.515 (23.275)	Loss2 7.875 (27.992)	Loss 85.2682 (303.1978)	MAE 2.075 (3.730)	
Epoch: [20 / 150]   [step 120/232]	Loss1 15.942 (23.645)	Loss2 17.156 (27.328)	Loss 187.5013 (296.9274)	MAE 3.338 (3.754)	
Epoch: [20 / 150]   [step 160/232]	Loss1 11.471 (25.068)	Loss2 22.386 (27.841)	Loss 235.3262 (303.4795)	MAE 2.680 (3.852)	
Epoch: [20 / 150]   [step 200/232]	Loss1 17.624 (24.431)	Loss2 17.799 (26.965)	Loss 195.6134 (294.0774)	MAE 2.994 (3.797)	
Valid: [steps 47], Loss 794.0741,  MAE:  5.2659

*learning rate 2.50e-04*

EarlyStopping counter: 1 out of 20


Epoch: [21 / 150]   [step 0/232]	Loss1 53.052 (53.052)	Loss2 32.460 (32.460)	Loss 377.6559 (377.6559)	MAE 6.376 (6.376)	
Epoch: [21 / 150]   [step 40/232]	Loss1 22.966 (21.644)	Loss2 21.801 (19.854)	Loss 240.9785 (220.1837)	MAE 4.038 (3.674)	
Epoch: [21 / 150]   [step 80/232]	Loss1 31.454 (20.371)	Loss2 19.355 (19.732)	Loss 225.0073 (217.6914)	MAE 5.007 (3.588)	
Epoch: [21 / 150]   [step 120/232]	Loss1 27.138 (20.966)	Loss2 43.904 (20.645)	Loss 466.1772 (227.4176)	MAE 4.011 (3.622)	
Epoch: [21 / 150]   [step 160/232]	Loss1 13.561 (21.088)	Loss2 8.685 (22.832)	Loss 100.4112 (249.4121)	MAE 3.073 (3.620)	
Epoch: [21 / 150]   [step 200/232]	Loss1 59.656 (22.363)	Loss2 30.685 (23.002)	Loss 366.5035 (252.3856)	MAE 6.923 (3.700)	
Valid: [steps 47], Loss 793.5189,  MAE:  4.8794

*learning rate 2.50e-04*

=======>   Best at epoch 21, valid MAE 4.879445

=======>   This is the best model !!! It has been saved!!!!!!


Epoch: [22 / 150]   [step 0/232]	Loss1 28.799 (28.799)	Loss2 8.072 (8.072)	Loss 109.5145 (109.5145)	MAE 5.006 (5.006)	
Epoch: [22 / 150]   [step 40/232]	Loss1 9.079 (18.034)	Loss2 14.444 (16.531)	Loss 153.5166 (183.3407)	MAE 1.999 (3.291)	
Epoch: [22 / 150]   [step 80/232]	Loss1 47.263 (20.350)	Loss2 12.314 (18.465)	Loss 170.4065 (204.9990)	MAE 6.326 (3.508)	
Epoch: [22 / 150]   [step 120/232]	Loss1 53.207 (21.357)	Loss2 10.032 (19.734)	Loss 153.5310 (218.7011)	MAE 6.472 (3.553)	
Epoch: [22 / 150]   [step 160/232]	Loss1 10.708 (21.785)	Loss2 17.814 (19.332)	Loss 188.8472 (215.1019)	MAE 2.602 (3.565)	
Epoch: [22 / 150]   [step 200/232]	Loss1 23.469 (21.346)	Loss2 28.362 (20.529)	Loss 307.0925 (226.6395)	MAE 3.978 (3.538)	
Valid: [steps 47], Loss 789.2939,  MAE:  5.5075

*learning rate 2.50e-04*

EarlyStopping counter: 1 out of 20


Epoch: [23 / 150]   [step 0/232]	Loss1 2.354 (2.354)	Loss2 6.861 (6.861)	Loss 70.9642 (70.9642)	MAE 1.197 (1.197)	
Epoch: [23 / 150]   [step 40/232]	Loss1 12.927 (18.219)	Loss2 30.499 (17.118)	Loss 317.9212 (189.4000)	MAE 2.972 (3.337)	
Epoch: [23 / 150]   [step 80/232]	Loss1 24.231 (21.468)	Loss2 16.618 (19.519)	Loss 190.4105 (216.6632)	MAE 4.331 (3.604)	
Epoch: [23 / 150]   [step 120/232]	Loss1 28.220 (22.373)	Loss2 25.028 (20.010)	Loss 278.5046 (222.4714)	MAE 4.453 (3.690)	
Epoch: [23 / 150]   [step 160/232]	Loss1 43.375 (23.825)	Loss2 8.098 (20.449)	Loss 124.3579 (228.3199)	MAE 5.946 (3.813)	
Epoch: [23 / 150]   [step 200/232]	Loss1 20.938 (22.998)	Loss2 13.459 (20.002)	Loss 155.5262 (223.0211)	MAE 4.284 (3.749)	
Valid: [steps 47], Loss 810.2078,  MAE:  4.8291

*learning rate 2.50e-04*

=======>   Best at epoch 23, valid MAE 4.829075

=======>   This is the best model !!! It has been saved!!!!!!


Epoch: [24 / 150]   [step 0/232]	Loss1 11.084 (11.084)	Loss2 17.781 (17.781)	Loss 188.8968 (188.8968)	MAE 2.511 (2.511)	
Epoch: [24 / 150]   [step 40/232]	Loss1 3.290 (25.475)	Loss2 9.904 (17.081)	Loss 102.3334 (196.2866)	MAE 1.377 (3.874)	
Epoch: [24 / 150]   [step 80/232]	Loss1 32.566 (23.622)	Loss2 16.770 (16.417)	Loss 200.2631 (187.7953)	MAE 4.602 (3.834)	
Epoch: [24 / 150]   [step 120/232]	Loss1 6.432 (22.821)	Loss2 11.503 (16.539)	Loss 121.4658 (188.2134)	MAE 2.050 (3.730)	
Epoch: [24 / 150]   [step 160/232]	Loss1 13.109 (22.377)	Loss2 17.062 (17.235)	Loss 183.7253 (194.7315)	MAE 3.073 (3.704)	
Epoch: [24 / 150]   [step 200/232]	Loss1 32.449 (21.996)	Loss2 14.181 (17.573)	Loss 174.2624 (197.7284)	MAE 5.090 (3.666)	
Valid: [steps 47], Loss 808.8792,  MAE:  4.8709

*learning rate 2.50e-04*

EarlyStopping counter: 1 out of 20


Epoch: [25 / 150]   [step 0/232]	Loss1 51.973 (51.973)	Loss2 11.518 (11.518)	Loss 167.1573 (167.1573)	MAE 6.300 (6.300)	
Epoch: [25 / 150]   [step 40/232]	Loss1 3.386 (21.312)	Loss2 2.618 (16.888)	Loss 29.5707 (190.1903)	MAE 1.497 (3.598)	
Epoch: [25 / 150]   [step 80/232]	Loss1 23.504 (21.114)	Loss2 25.622 (16.653)	Loss 279.7191 (187.6440)	MAE 3.843 (3.572)	
Epoch: [25 / 150]   [step 120/232]	Loss1 7.894 (21.036)	Loss2 4.369 (17.172)	Loss 51.5856 (192.7611)	MAE 2.326 (3.600)	
Epoch: [25 / 150]   [step 160/232]	Loss1 7.344 (19.466)	Loss2 13.757 (16.786)	Loss 144.9097 (187.3298)	MAE 2.196 (3.442)	
Epoch: [25 / 150]   [step 200/232]	Loss1 7.745 (18.988)	Loss2 2.618 (16.329)	Loss 33.9206 (182.2796)	MAE 2.501 (3.417)	
Valid: [steps 47], Loss 802.6768,  MAE:  5.7020

*learning rate 2.50e-04*

EarlyStopping counter: 2 out of 20


Epoch: [26 / 150]   [step 0/232]	Loss1 9.402 (9.402)	Loss2 14.071 (14.071)	Loss 150.1156 (150.1156)	MAE 2.460 (2.460)	
Epoch: [26 / 150]   [step 40/232]	Loss1 33.006 (14.745)	Loss2 21.607 (12.183)	Loss 249.0787 (136.5721)	MAE 4.946 (2.862)	
Epoch: [26 / 150]   [step 80/232]	Loss1 19.821 (16.830)	Loss2 10.308 (13.055)	Loss 122.9006 (147.3787)	MAE 3.843 (3.147)	
Epoch: [26 / 150]   [step 120/232]	Loss1 17.939 (19.955)	Loss2 9.647 (13.594)	Loss 114.4060 (155.8963)	MAE 3.512 (3.425)	
Epoch: [26 / 150]   [step 160/232]	Loss1 26.078 (20.624)	Loss2 24.265 (14.464)	Loss 268.7229 (165.2674)	MAE 4.388 (3.496)	
Epoch: [26 / 150]   [step 200/232]	Loss1 15.951 (19.648)	Loss2 7.551 (14.599)	Loss 91.4658 (165.6342)	MAE 3.175 (3.410)	
Valid: [steps 47], Loss 820.3774,  MAE:  5.2300

*learning rate 2.50e-04*

EarlyStopping counter: 3 out of 20


Epoch: [27 / 150]   [step 0/232]	Loss1 51.048 (51.048)	Loss2 20.018 (20.018)	Loss 251.2305 (251.2305)	MAE 6.462 (6.462)	
Epoch: [27 / 150]   [step 40/232]	Loss1 13.101 (21.805)	Loss2 10.490 (13.222)	Loss 117.9966 (154.0216)	MAE 3.051 (3.492)	
Epoch: [27 / 150]   [step 80/232]	Loss1 6.490 (19.223)	Loss2 9.105 (13.049)	Loss 97.5436 (149.7112)	MAE 1.918 (3.306)	
Epoch: [27 / 150]   [step 120/232]	Loss1 79.550 (18.288)	Loss2 12.314 (12.821)	Loss 202.6931 (146.4970)	MAE 8.291 (3.260)	
Epoch: [27 / 150]   [step 160/232]	Loss1 6.420 (17.698)	Loss2 17.337 (13.194)	Loss 179.7858 (149.6343)	MAE 2.214 (3.222)	
Epoch: [27 / 150]   [step 200/232]	Loss1 4.238 (18.489)	Loss2 9.055 (13.238)	Loss 94.7872 (150.8718)	MAE 1.627 (3.323)	
Valid: [steps 47], Loss 810.4962,  MAE:  4.9262

*learning rate 2.50e-04*

EarlyStopping counter: 4 out of 20


Epoch: [28 / 150]   [step 0/232]	Loss1 9.029 (9.029)	Loss2 9.529 (9.529)	Loss 104.3150 (104.3150)	MAE 2.489 (2.489)	
Epoch: [28 / 150]   [step 40/232]	Loss1 5.491 (14.117)	Loss2 7.177 (10.445)	Loss 77.2580 (118.5640)	MAE 1.922 (2.839)	
Epoch: [28 / 150]   [step 80/232]	Loss1 3.584 (15.761)	Loss2 7.429 (10.840)	Loss 77.8747 (124.1603)	MAE 1.575 (3.000)	
Epoch: [28 / 150]   [step 120/232]	Loss1 11.998 (15.847)	Loss2 11.499 (11.236)	Loss 126.9876 (128.2067)	MAE 2.601 (3.060)	
Epoch: [28 / 150]   [step 160/232]	Loss1 16.876 (15.914)	Loss2 9.252 (11.356)	Loss 109.3961 (129.4720)	MAE 3.705 (3.081)	
Epoch: [28 / 150]   [step 200/232]	Loss1 17.069 (16.835)	Loss2 13.058 (11.671)	Loss 147.6526 (133.5416)	MAE 3.550 (3.161)	
Valid: [steps 47], Loss 814.5893,  MAE:  4.9244

*learning rate 2.50e-04*

EarlyStopping counter: 5 out of 20


Epoch: [29 / 150]   [step 0/232]	Loss1 3.457 (3.457)	Loss2 12.808 (12.808)	Loss 131.5408 (131.5408)	MAE 1.491 (1.491)	
Epoch: [29 / 150]   [step 40/232]	Loss1 19.494 (17.977)	Loss2 17.959 (12.058)	Loss 199.0862 (138.5589)	MAE 3.713 (3.212)	
Epoch: [29 / 150]   [step 80/232]	Loss1 34.940 (18.805)	Loss2 10.057 (11.948)	Loss 135.5056 (138.2816)	MAE 5.428 (3.345)	
Epoch: [29 / 150]   [step 120/232]	Loss1 14.768 (18.208)	Loss2 16.415 (11.663)	Loss 178.9139 (134.8331)	MAE 3.260 (3.305)	
Epoch: [29 / 150]   [step 160/232]	Loss1 14.258 (17.264)	Loss2 14.728 (11.729)	Loss 161.5351 (134.5495)	MAE 3.090 (3.228)	
Epoch: [29 / 150]   [step 200/232]	Loss1 31.883 (16.457)	Loss2 21.073 (11.356)	Loss 242.6114 (130.0140)	MAE 4.780 (3.154)	
Valid: [steps 47], Loss 707.1389,  MAE:  5.4735

*learning rate 1.25e-04*

EarlyStopping counter: 6 out of 20


Epoch: [30 / 150]   [step 0/232]	Loss1 1.925 (1.925)	Loss2 2.611 (2.611)	Loss 28.0335 (28.0335)	MAE 1.136 (1.136)	
Epoch: [30 / 150]   [step 40/232]	Loss1 6.382 (15.180)	Loss2 17.349 (9.104)	Loss 179.8678 (106.2236)	MAE 2.051 (3.018)	
Epoch: [30 / 150]   [step 80/232]	Loss1 4.482 (15.689)	Loss2 4.387 (8.564)	Loss 48.3557 (101.3283)	MAE 1.832 (3.118)	
Epoch: [30 / 150]   [step 120/232]	Loss1 41.868 (15.838)	Loss2 6.235 (8.717)	Loss 104.2194 (103.0112)	MAE 6.153 (3.104)	
Epoch: [30 / 150]   [step 160/232]	Loss1 16.107 (15.051)	Loss2 7.344 (8.468)	Loss 89.5515 (99.7353)	MAE 3.552 (3.041)	
Epoch: [30 / 150]   [step 200/232]	Loss1 9.825 (14.280)	Loss2 4.343 (8.226)	Loss 53.2572 (96.5450)	MAE 2.768 (2.956)	
Valid: [steps 47], Loss 850.2184,  MAE:  4.7930

*learning rate 1.25e-04*

=======>   Best at epoch 30, valid MAE 4.792984

=======>   This is the best model !!! It has been saved!!!!!!


Epoch: [31 / 150]   [step 0/232]	Loss1 15.118 (15.118)	Loss2 3.994 (3.994)	Loss 55.0548 (55.0548)	MAE 3.509 (3.509)	
Epoch: [31 / 150]   [step 40/232]	Loss1 7.403 (11.867)	Loss2 6.531 (6.511)	Loss 72.7174 (76.9776)	MAE 2.282 (2.660)	
Epoch: [31 / 150]   [step 80/232]	Loss1 8.943 (9.660)	Loss2 10.253 (6.260)	Loss 111.4697 (72.2638)	MAE 2.754 (2.416)	
Epoch: [31 / 150]   [step 120/232]	Loss1 45.515 (11.886)	Loss2 19.901 (6.851)	Loss 244.5270 (80.3913)	MAE 6.084 (2.691)	
Epoch: [31 / 150]   [step 160/232]	Loss1 6.769 (12.352)	Loss2 3.302 (6.963)	Loss 39.7893 (81.9812)	MAE 2.110 (2.762)	
Epoch: [31 / 150]   [step 200/232]	Loss1 7.257 (12.835)	Loss2 4.104 (7.008)	Loss 48.2937 (82.9182)	MAE 2.325 (2.802)	
Valid: [steps 47], Loss 761.3799,  MAE:  5.1022

*learning rate 1.25e-04*

EarlyStopping counter: 1 out of 20


Epoch: [32 / 150]   [step 0/232]	Loss1 22.474 (22.474)	Loss2 8.761 (8.761)	Loss 110.0874 (110.0874)	MAE 4.395 (4.395)	
Epoch: [32 / 150]   [step 40/232]	Loss1 4.139 (11.178)	Loss2 2.624 (6.435)	Loss 30.3753 (75.5287)	MAE 1.793 (2.532)	
Epoch: [32 / 150]   [step 80/232]	Loss1 5.870 (11.428)	Loss2 3.766 (5.887)	Loss 43.5278 (70.2945)	MAE 2.117 (2.584)	
Epoch: [32 / 150]   [step 120/232]	Loss1 3.262 (10.934)	Loss2 4.953 (6.127)	Loss 52.7956 (72.2040)	MAE 1.452 (2.560)	
Epoch: [32 / 150]   [step 160/232]	Loss1 39.637 (11.110)	Loss2 6.637 (6.217)	Loss 106.0100 (73.2840)	MAE 5.779 (2.591)	
Epoch: [32 / 150]   [step 200/232]	Loss1 4.526 (11.944)	Loss2 3.508 (6.622)	Loss 39.6054 (78.1665)	MAE 1.685 (2.714)	
Valid: [steps 47], Loss 738.6057,  MAE:  4.8188

*learning rate 1.25e-04*

EarlyStopping counter: 2 out of 20


Epoch: [33 / 150]   [step 0/232]	Loss1 8.964 (8.964)	Loss2 8.802 (8.802)	Loss 96.9843 (96.9843)	MAE 2.589 (2.589)	
Epoch: [33 / 150]   [step 40/232]	Loss1 59.560 (14.321)	Loss2 5.192 (5.545)	Loss 111.4815 (69.7739)	MAE 7.492 (3.008)	
Epoch: [33 / 150]   [step 80/232]	Loss1 5.138 (14.267)	Loss2 13.321 (6.323)	Loss 138.3515 (77.4926)	MAE 1.877 (3.021)	
Epoch: [33 / 150]   [step 120/232]	Loss1 2.562 (14.766)	Loss2 4.730 (6.076)	Loss 49.8599 (75.5284)	MAE 1.248 (3.034)	
Epoch: [33 / 150]   [step 160/232]	Loss1 20.732 (15.692)	Loss2 6.760 (6.296)	Loss 88.3345 (78.6484)	MAE 4.096 (3.116)	
Epoch: [33 / 150]   [step 200/232]	Loss1 19.437 (15.627)	Loss2 4.997 (6.264)	Loss 69.4029 (78.2640)	MAE 4.180 (3.093)	
Valid: [steps 47], Loss 781.0798,  MAE:  5.0342

*learning rate 1.25e-04*

EarlyStopping counter: 3 out of 20


Epoch: [34 / 150]   [step 0/232]	Loss1 2.258 (2.258)	Loss2 2.646 (2.646)	Loss 28.7217 (28.7217)	MAE 1.104 (1.104)	
Epoch: [34 / 150]   [step 40/232]	Loss1 12.668 (9.237)	Loss2 2.388 (4.203)	Loss 36.5446 (51.2619)	MAE 3.379 (2.358)	
Epoch: [34 / 150]   [step 80/232]	Loss1 13.577 (9.013)	Loss2 6.467 (4.649)	Loss 78.2505 (55.5058)	MAE 3.294 (2.369)	
Epoch: [34 / 150]   [step 120/232]	Loss1 15.464 (10.331)	Loss2 5.845 (4.815)	Loss 73.9177 (58.4788)	MAE 3.336 (2.548)	
Epoch: [34 / 150]   [step 160/232]	Loss1 2.046 (10.842)	Loss2 3.292 (4.984)	Loss 34.9678 (60.6773)	MAE 1.014 (2.594)	
Epoch: [34 / 150]   [step 200/232]	Loss1 2.546 (11.156)	Loss2 3.132 (5.024)	Loss 33.8631 (61.3954)	MAE 1.386 (2.636)	
Valid: [steps 47], Loss 741.2855,  MAE:  5.0748

*learning rate 1.25e-04*

EarlyStopping counter: 4 out of 20


Epoch: [35 / 150]   [step 0/232]	Loss1 21.722 (21.722)	Loss2 6.659 (6.659)	Loss 88.3092 (88.3092)	MAE 4.276 (4.276)	
Epoch: [35 / 150]   [step 40/232]	Loss1 10.086 (14.813)	Loss2 12.621 (5.130)	Loss 136.2914 (66.1141)	MAE 2.566 (3.013)	
Epoch: [35 / 150]   [step 80/232]	Loss1 1.612 (13.780)	Loss2 5.236 (5.004)	Loss 53.9746 (63.8172)	MAE 1.056 (2.888)	
Epoch: [35 / 150]   [step 120/232]	Loss1 28.483 (12.588)	Loss2 8.886 (4.891)	Loss 117.3422 (61.4966)	MAE 4.829 (2.785)	
Epoch: [35 / 150]   [step 160/232]	Loss1 16.560 (12.697)	Loss2 3.364 (5.041)	Loss 50.1992 (63.1112)	MAE 3.734 (2.826)	
Epoch: [35 / 150]   [step 200/232]	Loss1 12.266 (11.720)	Loss2 5.471 (4.970)	Loss 66.9734 (61.4191)	MAE 3.149 (2.708)	
Valid: [steps 47], Loss 765.9451,  MAE:  4.9478

*learning rate 1.25e-04*

EarlyStopping counter: 5 out of 20


Epoch: [36 / 150]   [step 0/232]	Loss1 21.546 (21.546)	Loss2 1.738 (1.738)	Loss 38.9222 (38.9222)	MAE 4.499 (4.499)	
Epoch: [36 / 150]   [step 40/232]	Loss1 3.973 (13.859)	Loss2 1.978 (4.224)	Loss 23.7499 (56.1025)	MAE 1.721 (2.804)	
Epoch: [36 / 150]   [step 80/232]	Loss1 5.687 (15.144)	Loss2 4.881 (4.170)	Loss 54.5024 (56.8406)	MAE 1.941 (2.923)	
Epoch: [36 / 150]   [step 120/232]	Loss1 59.403 (15.879)	Loss2 4.369 (4.265)	Loss 103.0947 (58.5259)	MAE 7.550 (2.960)	
Epoch: [36 / 150]   [step 160/232]	Loss1 1.369 (15.013)	Loss2 3.398 (4.396)	Loss 35.3520 (58.9732)	MAE 1.026 (2.934)	
Epoch: [36 / 150]   [step 200/232]	Loss1 40.918 (14.182)	Loss2 4.503 (4.385)	Loss 85.9438 (58.0331)	MAE 6.245 (2.856)	
Valid: [steps 47], Loss 789.9893,  MAE:  4.9319

*learning rate 6.25e-05*

EarlyStopping counter: 6 out of 20


Epoch: [37 / 150]   [step 0/232]	Loss1 89.947 (89.947)	Loss2 6.784 (6.784)	Loss 157.7919 (157.7919)	MAE 9.273 (9.273)	
Epoch: [37 / 150]   [step 40/232]	Loss1 1.549 (13.557)	Loss2 1.669 (3.672)	Loss 18.2433 (50.2720)	MAE 1.015 (2.818)	
Epoch: [37 / 150]   [step 80/232]	Loss1 1.364 (13.610)	Loss2 2.890 (3.691)	Loss 30.2629 (50.5209)	MAE 0.887 (2.847)	
Epoch: [37 / 150]   [step 120/232]	Loss1 34.212 (15.537)	Loss2 5.540 (3.974)	Loss 89.6142 (55.2788)	MAE 5.575 (3.065)	
Epoch: [37 / 150]   [step 160/232]	Loss1 10.046 (14.471)	Loss2 2.949 (3.777)	Loss 39.5384 (52.2400)	MAE 2.831 (2.928)	
Epoch: [37 / 150]   [step 200/232]	Loss1 0.905 (13.879)	Loss2 1.095 (3.735)	Loss 11.8507 (51.2253)	MAE 0.667 (2.882)	
Valid: [steps 47], Loss 806.3192,  MAE:  4.9456

*learning rate 6.25e-05*

EarlyStopping counter: 7 out of 20


Epoch: [38 / 150]   [step 0/232]	Loss1 0.507 (0.507)	Loss2 1.142 (1.142)	Loss 11.9222 (11.9222)	MAE 0.586 (0.586)	
Epoch: [38 / 150]   [step 40/232]	Loss1 21.806 (9.618)	Loss2 3.015 (2.865)	Loss 51.9611 (38.2727)	MAE 4.507 (2.352)	
Epoch: [38 / 150]   [step 80/232]	Loss1 3.640 (11.466)	Loss2 1.347 (3.082)	Loss 17.1100 (42.2891)	MAE 1.760 (2.524)	
Epoch: [38 / 150]   [step 120/232]	Loss1 3.755 (11.326)	Loss2 1.703 (3.348)	Loss 20.7824 (44.8037)	MAE 1.743 (2.507)	
Epoch: [38 / 150]   [step 160/232]	Loss1 2.543 (11.785)	Loss2 3.198 (3.316)	Loss 34.5257 (44.9403)	MAE 1.307 (2.625)	
Epoch: [38 / 150]   [step 200/232]	Loss1 6.066 (11.280)	Loss2 2.788 (3.356)	Loss 33.9480 (44.8448)	MAE 2.265 (2.591)	
Valid: [steps 47], Loss 785.9688,  MAE:  4.9273

*learning rate 6.25e-05*

EarlyStopping counter: 8 out of 20


Epoch: [39 / 150]   [step 0/232]	Loss1 5.469 (5.469)	Loss2 6.844 (6.844)	Loss 73.9065 (73.9065)	MAE 1.947 (1.947)	
Epoch: [39 / 150]   [step 40/232]	Loss1 1.257 (13.979)	Loss2 2.348 (3.235)	Loss 24.7338 (46.3283)	MAE 0.895 (2.797)	
Epoch: [39 / 150]   [step 80/232]	Loss1 14.654 (12.676)	Loss2 4.705 (3.446)	Loss 61.7049 (47.1363)	MAE 3.542 (2.776)	
Epoch: [39 / 150]   [step 120/232]	Loss1 28.038 (12.352)	Loss2 6.422 (3.287)	Loss 92.2557 (45.2245)	MAE 5.039 (2.724)	
Epoch: [39 / 150]   [step 160/232]	Loss1 31.491 (13.657)	Loss2 7.917 (3.424)	Loss 110.6657 (47.9018)	MAE 5.407 (2.849)	
Epoch: [39 / 150]   [step 200/232]	Loss1 1.850 (12.981)	Loss2 1.304 (3.303)	Loss 14.8910 (46.0057)	MAE 1.039 (2.763)	
Valid: [steps 47], Loss 787.1816,  MAE:  4.8670

*learning rate 6.25e-05*

EarlyStopping counter: 9 out of 20


Epoch: [40 / 150]   [step 0/232]	Loss1 16.946 (16.946)	Loss2 2.096 (2.096)	Loss 37.9071 (37.9071)	MAE 4.001 (4.001)	
Epoch: [40 / 150]   [step 40/232]	Loss1 8.507 (11.604)	Loss2 2.612 (3.000)	Loss 34.6255 (41.6082)	MAE 2.550 (2.859)	
Epoch: [40 / 150]   [step 80/232]	Loss1 3.865 (12.057)	Loss2 1.800 (3.112)	Loss 21.8630 (43.1789)	MAE 1.791 (2.845)	
Epoch: [40 / 150]   [step 120/232]	Loss1 10.289 (11.315)	Loss2 3.250 (3.079)	Loss 42.7924 (42.1053)	MAE 3.065 (2.739)	
Epoch: [40 / 150]   [step 160/232]	Loss1 1.683 (11.559)	Loss2 1.193 (3.095)	Loss 13.6113 (42.5143)	MAE 1.022 (2.753)	
Epoch: [40 / 150]   [step 200/232]	Loss1 11.295 (11.848)	Loss2 3.849 (3.059)	Loss 49.7852 (42.4332)	MAE 3.078 (2.797)	
Valid: [steps 47], Loss 867.3080,  MAE:  4.8986

*learning rate 6.25e-05*

EarlyStopping counter: 10 out of 20


Epoch: [41 / 150]   [step 0/232]	Loss1 10.617 (10.617)	Loss2 4.762 (4.762)	Loss 58.2423 (58.2423)	MAE 3.012 (3.012)	
Epoch: [41 / 150]   [step 40/232]	Loss1 14.850 (9.189)	Loss2 2.109 (2.509)	Loss 35.9353 (34.2801)	MAE 3.702 (2.525)	
Epoch: [41 / 150]   [step 80/232]	Loss1 11.552 (9.776)	Loss2 2.951 (2.477)	Loss 41.0657 (34.5479)	MAE 3.232 (2.605)	
Epoch: [41 / 150]   [step 120/232]	Loss1 9.593 (10.038)	Loss2 6.040 (2.753)	Loss 69.9947 (37.5718)	MAE 2.647 (2.588)	
Epoch: [41 / 150]   [step 160/232]	Loss1 9.360 (10.177)	Loss2 3.642 (2.697)	Loss 45.7844 (37.1437)	MAE 2.860 (2.607)	
Epoch: [41 / 150]   [step 200/232]	Loss1 18.380 (10.158)	Loss2 4.205 (2.734)	Loss 60.4248 (37.5003)	MAE 4.082 (2.602)	
Valid: [steps 47], Loss 778.6676,  MAE:  4.8585

*learning rate 6.25e-05*

EarlyStopping counter: 11 out of 20


Epoch: [42 / 150]   [step 0/232]	Loss1 15.727 (15.727)	Loss2 3.069 (3.069)	Loss 46.4215 (46.4215)	MAE 3.827 (3.827)	
Epoch: [42 / 150]   [step 40/232]	Loss1 10.134 (13.002)	Loss2 0.927 (2.875)	Loss 19.4039 (41.7487)	MAE 2.987 (2.897)	
Epoch: [42 / 150]   [step 80/232]	Loss1 5.227 (11.788)	Loss2 0.600 (2.848)	Loss 11.2247 (40.2657)	MAE 2.204 (2.742)	
Epoch: [42 / 150]   [step 120/232]	Loss1 27.179 (11.605)	Loss2 3.700 (2.922)	Loss 64.1745 (40.8196)	MAE 4.923 (2.730)	
Epoch: [42 / 150]   [step 160/232]	Loss1 6.482 (10.676)	Loss2 0.607 (2.822)	Loss 12.5470 (38.8976)	MAE 2.459 (2.581)	
Epoch: [42 / 150]   [step 200/232]	Loss1 0.902 (11.555)	Loss2 0.516 (2.805)	Loss 6.0627 (39.6033)	MAE 0.641 (2.672)	
Valid: [steps 47], Loss 753.2207,  MAE:  4.8919

*learning rate 3.13e-05*

EarlyStopping counter: 12 out of 20


Epoch: [43 / 150]   [step 0/232]	Loss1 17.817 (17.817)	Loss2 0.964 (0.964)	Loss 27.4580 (27.4580)	MAE 4.157 (4.157)	
Epoch: [43 / 150]   [step 40/232]	Loss1 2.257 (10.178)	Loss2 0.927 (2.136)	Loss 11.5240 (31.5346)	MAE 1.379 (2.562)	
Epoch: [43 / 150]   [step 80/232]	Loss1 2.395 (10.457)	Loss2 1.119 (2.152)	Loss 13.5804 (31.9793)	MAE 1.365 (2.587)	
Epoch: [43 / 150]   [step 120/232]	Loss1 1.914 (10.724)	Loss2 1.917 (2.270)	Loss 21.0791 (33.4194)	MAE 1.133 (2.577)	
Epoch: [43 / 150]   [step 160/232]	Loss1 2.652 (11.167)	Loss2 1.539 (2.527)	Loss 18.0427 (36.4369)	MAE 1.412 (2.655)	
Epoch: [43 / 150]   [step 200/232]	Loss1 0.955 (10.983)	Loss2 0.584 (2.486)	Loss 6.7966 (35.8459)	MAE 0.736 (2.612)	
Valid: [steps 47], Loss 795.7371,  MAE:  4.9006

*learning rate 3.13e-05*

EarlyStopping counter: 13 out of 20


Epoch: [44 / 150]   [step 0/232]	Loss1 7.359 (7.359)	Loss2 1.991 (1.991)	Loss 27.2663 (27.2663)	MAE 2.579 (2.579)	
Epoch: [44 / 150]   [step 40/232]	Loss1 1.365 (13.421)	Loss2 3.565 (2.688)	Loss 37.0138 (40.3016)	MAE 0.866 (2.891)	
Epoch: [44 / 150]   [step 80/232]	Loss1 21.695 (14.427)	Loss2 2.228 (2.690)	Loss 43.9736 (41.3290)	MAE 4.575 (3.046)	
Epoch: [44 / 150]   [step 120/232]	Loss1 1.894 (12.778)	Loss2 0.613 (2.681)	Loss 8.0236 (39.5921)	MAE 1.216 (2.860)	
Epoch: [44 / 150]   [step 160/232]	Loss1 18.084 (13.197)	Loss2 3.710 (2.727)	Loss 55.1814 (40.4698)	MAE 3.964 (2.880)	
Epoch: [44 / 150]   [step 200/232]	Loss1 17.597 (12.501)	Loss2 1.541 (2.576)	Loss 33.0075 (38.2642)	MAE 4.112 (2.818)	
Valid: [steps 47], Loss 805.7682,  MAE:  4.9237

*learning rate 3.13e-05*

EarlyStopping counter: 14 out of 20


Epoch: [45 / 150]   [step 0/232]	Loss1 19.559 (19.559)	Loss2 1.253 (1.253)	Loss 32.0864 (32.0864)	MAE 4.252 (4.252)	
Epoch: [45 / 150]   [step 40/232]	Loss1 23.273 (13.991)	Loss2 3.228 (2.233)	Loss 55.5574 (36.3156)	MAE 4.668 (3.015)	
Epoch: [45 / 150]   [step 80/232]	Loss1 17.381 (10.803)	Loss2 1.924 (2.187)	Loss 36.6254 (32.6776)	MAE 4.101 (2.560)	
Epoch: [45 / 150]   [step 120/232]	Loss1 56.723 (10.817)	Loss2 7.322 (2.187)	Loss 129.9439 (32.6857)	MAE 7.353 (2.574)	
Epoch: [45 / 150]   [step 160/232]	Loss1 2.471 (10.547)	Loss2 0.577 (2.171)	Loss 8.2379 (32.2573)	MAE 1.481 (2.562)	
Epoch: [45 / 150]   [step 200/232]	Loss1 4.167 (10.251)	Loss2 2.190 (2.141)	Loss 26.0664 (31.6606)	MAE 1.746 (2.541)	
Valid: [steps 47], Loss 747.4898,  MAE:  4.9313

*learning rate 3.13e-05*

EarlyStopping counter: 15 out of 20


Epoch: [46 / 150]   [step 0/232]	Loss1 5.547 (5.547)	Loss2 1.610 (1.610)	Loss 21.6509 (21.6509)	MAE 2.167 (2.167)	
Epoch: [46 / 150]   [step 40/232]	Loss1 1.041 (11.268)	Loss2 1.700 (2.424)	Loss 18.0444 (35.5061)	MAE 0.870 (2.569)	
Epoch: [46 / 150]   [step 80/232]	Loss1 7.122 (12.965)	Loss2 0.638 (2.200)	Loss 13.5029 (34.9613)	MAE 2.626 (2.801)	
Epoch: [46 / 150]   [step 120/232]	Loss1 0.810 (12.126)	Loss2 1.549 (2.200)	Loss 16.3011 (34.1262)	MAE 0.687 (2.738)	
Epoch: [46 / 150]   [step 160/232]	Loss1 16.087 (12.064)	Loss2 1.899 (2.195)	Loss 35.0809 (34.0102)	MAE 3.902 (2.754)	
Epoch: [46 / 150]   [step 200/232]	Loss1 10.484 (12.339)	Loss2 4.075 (2.222)	Loss 51.2388 (34.5607)	MAE 2.978 (2.745)	
Valid: [steps 47], Loss 756.4377,  MAE:  4.9565

*learning rate 3.13e-05*

EarlyStopping counter: 16 out of 20


Epoch: [47 / 150]   [step 0/232]	Loss1 6.177 (6.177)	Loss2 3.779 (3.779)	Loss 43.9697 (43.9697)	MAE 2.305 (2.305)	
Epoch: [47 / 150]   [step 40/232]	Loss1 10.261 (9.294)	Loss2 2.066 (2.107)	Loss 30.9227 (30.3646)	MAE 3.068 (2.450)	
Epoch: [47 / 150]   [step 80/232]	Loss1 17.885 (10.737)	Loss2 1.819 (2.245)	Loss 36.0741 (33.1856)	MAE 4.128 (2.572)	
Epoch: [47 / 150]   [step 120/232]	Loss1 2.538 (10.759)	Loss2 1.487 (2.230)	Loss 17.4063 (33.0610)	MAE 1.437 (2.567)	
Epoch: [47 / 150]   [step 160/232]	Loss1 2.774 (10.163)	Loss2 0.916 (2.202)	Loss 11.9366 (32.1843)	MAE 1.516 (2.486)	
Epoch: [47 / 150]   [step 200/232]	Loss1 0.918 (10.323)	Loss2 0.941 (2.231)	Loss 10.3295 (32.6359)	MAE 0.803 (2.517)	
Valid: [steps 47], Loss 783.7280,  MAE:  4.8863

*learning rate 3.13e-05*

EarlyStopping counter: 17 out of 20


Epoch: [48 / 150]   [step 0/232]	Loss1 3.635 (3.635)	Loss2 6.900 (6.900)	Loss 72.6365 (72.6365)	MAE 1.525 (1.525)	
Epoch: [48 / 150]   [step 40/232]	Loss1 8.966 (11.114)	Loss2 1.121 (2.226)	Loss 20.1801 (33.3695)	MAE 2.904 (2.742)	
Epoch: [48 / 150]   [step 80/232]	Loss1 0.992 (12.938)	Loss2 0.587 (2.336)	Loss 6.8645 (36.3025)	MAE 0.793 (2.792)	
Epoch: [48 / 150]   [step 120/232]	Loss1 2.745 (10.982)	Loss2 2.145 (2.243)	Loss 24.1917 (33.4089)	MAE 1.473 (2.555)	
Epoch: [48 / 150]   [step 160/232]	Loss1 3.019 (10.884)	Loss2 1.192 (2.145)	Loss 14.9426 (32.3384)	MAE 1.537 (2.568)	
Epoch: [48 / 150]   [step 200/232]	Loss1 2.245 (10.595)	Loss2 1.059 (2.177)	Loss 12.8389 (32.3607)	MAE 1.339 (2.554)	
Valid: [steps 47], Loss 804.6240,  MAE:  4.9658

*learning rate 1.56e-05*

EarlyStopping counter: 18 out of 20


Epoch: [49 / 150]   [step 0/232]	Loss1 3.120 (3.120)	Loss2 0.700 (0.700)	Loss 10.1165 (10.1165)	MAE 1.653 (1.653)	
Epoch: [49 / 150]   [step 40/232]	Loss1 5.285 (12.551)	Loss2 0.817 (1.929)	Loss 13.4539 (31.8382)	MAE 2.178 (2.893)	
Epoch: [49 / 150]   [step 80/232]	Loss1 2.689 (12.025)	Loss2 1.404 (2.025)	Loss 16.7319 (32.2724)	MAE 1.461 (2.754)	
Epoch: [49 / 150]   [step 120/232]	Loss1 12.698 (11.421)	Loss2 1.318 (2.019)	Loss 25.8778 (31.6077)	MAE 3.454 (2.725)	
Epoch: [49 / 150]   [step 160/232]	Loss1 3.154 (10.449)	Loss2 1.015 (1.927)	Loss 13.3039 (29.7160)	MAE 1.620 (2.587)	
Epoch: [49 / 150]   [step 200/232]	Loss1 4.979 (10.613)	Loss2 0.884 (2.000)	Loss 13.8192 (30.6098)	MAE 2.159 (2.568)	
Valid: [steps 47], Loss 786.3482,  MAE:  4.9308

*learning rate 1.56e-05*

EarlyStopping counter: 19 out of 20


Epoch: [50 / 150]   [step 0/232]	Loss1 27.844 (27.844)	Loss2 1.184 (1.184)	Loss 39.6798 (39.6798)	MAE 5.205 (5.205)	
Epoch: [50 / 150]   [step 40/232]	Loss1 4.428 (10.343)	Loss2 0.633 (1.880)	Loss 10.7555 (29.1422)	MAE 1.907 (2.547)	
Epoch: [50 / 150]   [step 80/232]	Loss1 56.827 (13.005)	Loss2 2.890 (2.124)	Loss 85.7304 (34.2493)	MAE 7.366 (2.892)	
Epoch: [50 / 150]   [step 120/232]	Loss1 18.380 (11.592)	Loss2 1.639 (1.960)	Loss 34.7684 (31.1916)	MAE 4.143 (2.694)	
Epoch: [50 / 150]   [step 160/232]	Loss1 1.787 (10.797)	Loss2 0.704 (1.948)	Loss 8.8289 (30.2743)	MAE 1.193 (2.587)	
Epoch: [50 / 150]   [step 200/232]	Loss1 1.446 (11.154)	Loss2 1.531 (1.928)	Loss 16.7518 (30.4341)	MAE 1.090 (2.637)	
Valid: [steps 47], Loss 661.9005,  MAE:  4.9317

*learning rate 1.56e-05*

EarlyStopping counter: 20 out of 20


======= Early stopping =======
Epo - Mtc
Traceback (most recent call last):
  File "/home/canhdx/workspace/TSAN-brain-age-estimation/TSAN/train_first_stage.py", line 406, in <module>
    main(res)
  File "/home/canhdx/workspace/TSAN-brain-age-estimation/TSAN/train_first_stage.py", line 163, in main
    mtc_epo = dict(zip(saved_metrics, saved_epos))
NameError: name 'saved_metrics' is not defined
